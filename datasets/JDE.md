# Dataset Zoo for JDE

Here are several datasets for training and evaluating the Joint Detection and Embedding (JDE) model. Annotations are provided in a unified format. 

## Data Format

Each dataset should have the following structure:
```
<Dataset>
   |——————images
   |        └——————00001.jpg
   |        |—————— ...
   |        └——————0000N.jpg
   |
   └——————labels_with_ids
            └——————00001.txt
            |—————— ...
            └——————0000N.txt
```
Every image has a corresponding annotation text. Given an image path, 
the annotation text path can be generated by replacing `images` with `labels_with_ids` and `.jpg` with `.txt`.

In the annotation text, each line is describing a bounding box and has the following format:
```
[class] [identity] [x_center] [y_center] [width] [height]
```
The field `[class]` should be `0`. Only single-class multi-object tracking is supported in this version. 

The field `[identity]` is an integer from `0` to `num_identities - 1`, or `-1` if this box has no identity annotation.

**Note** that the values of `[x_center] [y_center] [width] [height]` are normalized by the width / height of the image, so they are floating-point numbers ranging from 0 to 1.

## Caltech Pedestrian

### Download

In original webpage [CaltechPedestrians](https://data.caltech.edu/records/f6rph-90m20), download [data_and_labels.zip](https://data.caltech.edu/records/f6rph-90m20/files/data_and_labels.zip?download=1).

Download [Converter](https://github.com/mitmul/caltech-pedestrian-dataset-converter) to convert the original data format to jpeg images.

Or use [DbCollection](https://dbcollection.readthedocs.io/en/latest/datasets/caltech_ped.html) with different format.

### Format
```
CaltechPedestrians/preprocessed
   |
   |——————images
   |        └——————set00_V000_0.png
   |        |—————— ...
   |        └——————setXX_Vxxx_N.png
   |        
   └——————labels
            └——————set00_V000_0.txt
            |—————— ...
            └——————setXX_Vxxx_N.txt
```

### Citation
```
@inproceedings{ dollarCVPR09peds,
       author = "P. Doll\'ar and C. Wojek and B. Schiele and  P. Perona",
       title = "Pedestrian Detection: A Benchmark",
       booktitle = "CVPR",
       month = "June",
       year = "2009",
       city = "Miami",
}
```

## CityPersons

### Download

Download from output of this [Kaggle notebook](https://www.kaggle.com/code/wildred/city-persons-dataset).

It is extracted from original [CityScapes](https://www.kaggle.com/datasets/kavithak1388/cityscapes).

### Format
```
CityPersons/preprocessed/{train/val}
   |
   |——————images
   |        |—————— ...
   |        └——————{location}_xxxxxx_xxxxxx_leftImg8bit.png
   |        
   └——————labels
            |—————— ...
            └——————{location}_xxxxxx_xxxxxx_leftImg8bit.txt
```

### Citation
```
@INPROCEEDINGS{Shanshan2017CVPR,
  Author = {Shanshan Zhang and Rodrigo Benenson and Bernt Schiele},
  Title = {CityPersons: A Diverse Dataset for Pedestrian Detection},
  Booktitle = {CVPR},
  Year = {2017}
 }

@INPROCEEDINGS{Cordts2016Cityscapes,
title={The Cityscapes Dataset for Semantic Urban Scene Understanding},
author={Cordts, Marius and Omran, Mohamed and Ramos, Sebastian and Rehfeld, Timo and Enzweiler, Markus and Benenson, Rodrigo and Franke, Uwe and Roth, Stefan and Schiele, Bernt},
booktitle={Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
year={2016}
}
```

## CUHK-SYSU

Google Drive:
[[0]](https://drive.google.com/file/d/1D7VL43kIV9uJrdSCYl53j89RE2K-IoQA/view?usp=sharing)

Original dataset webpage: [CUHK-SYSU Person Search Dataset](http://www.ee.cuhk.edu.hk/~xgwang/PS/dataset.html)

```
@inproceedings{xiaoli2017joint,
  title={Joint Detection and Identification Feature Learning for Person Search},
  author={Xiao, Tong and Li, Shuang and Wang, Bochao and Lin, Liang and Wang, Xiaogang},
  booktitle={CVPR},
  year={2017}
}
```

## PRW

Google Drive:
[[0]](https://drive.google.com/file/d/116_mIdjgB-WJXGe8RYJDWxlFnc_4sqS8/view?usp=sharing)

Original dataset webpage: [Person Search in the Wild datset](http://www.liangzheng.com.cn/Project/project_prw.html)

```
@inproceedings{zheng2017person,
  title={Person re-identification in the wild},
  author={Zheng, Liang and Zhang, Hengheng and Sun, Shaoyan and Chandraker, Manmohan and Yang, Yi and Tian, Qi},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={1367--1376},
  year={2017}
}
```

## ETHZ:

Google Drive:
[[0]](https://drive.google.com/file/d/19QyGOCqn8K_rc9TXJ8UwLSxCx17e0GoY/view?usp=sharing)

Original dataset webpage: [ETHZ pedestrian datset](https://data.vision.ee.ethz.ch/cvl/aess/dataset/)

```
@InProceedings{eth_biwi_00534,
author = {A. Ess and B. Leibe and K. Schindler and and L. van Gool},
title = {A Mobile Vision System for Robust Multi-Person Tracking},
booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR'08)},
year = {2008},
month = {June},
publisher = {IEEE Press},
keywords = {}
}
```

## MOT

### MOT-17

Google Drive:
[[0]](https://drive.google.com/file/d/1ET-6w12yHNo8DKevOVgK1dBlYs739e_3/view?usp=sharing)

Original dataset webpage: [MOT-17](https://motchallenge.net/data/MOT17/)

### MOT-16 (for evaluation)

Google Drive:
[[0]](https://drive.google.com/file/d/1254q3ruzBzgn4LUejDVsCtT05SIEieQg/view?usp=sharing)

Original dataset webpage: [MOT-16](https://motchallenge.net/data/MOT16/)

### Citation
```
@article{milan2016mot16,
  title={MOT16: A benchmark for multi-object tracking},
  author={Milan, Anton and Leal-Taix{\'e}, Laura and Reid, Ian and Roth, Stefan and Schindler, Konrad},
  journal={arXiv preprint arXiv:1603.00831},
  year={2016}
}
```

